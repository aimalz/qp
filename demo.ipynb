{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `qp` Demo\n",
    "\n",
    "In this notebook we use the `qp` module to approximate some standard 1-D PDFs using sets of quantiles, and assess the accuracy of the quantile parametrization(TM).\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To run `qp`, you will need to first install the module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import scipy.interpolate as spi\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `qp.PDF` Class\n",
    "\n",
    "This is the basic element of `qp` - an object representing a probability density function. This class is stored in the module `pdf.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! cat qp/pdf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating a Gaussian\n",
    "\n",
    "Let's summon a PDF object, and initialize it with a standard function - a Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist = sps.norm(loc=0, scale=1)\n",
    "P = qp.PDF(truth=dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute a set of evenly spaced quantiles. These will be carried by the `PDF` object as `p.quantiles`.  We also demonstrate the initialization of a 'PDF' object with quantiles and no truth function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantiles = P.quantize(percent=10.)\n",
    "Q = qp.PDF(quantiles=quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute a histogram representation that will be carried by the 'PDF' object as 'p.histogram'.  We can similary initialize a 'PDF' object with a histogram and no truth function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = qp.PDF(truth=dist)\n",
    "histogram = T.histogramize(nbins=10, binrange=[-2., 2.])\n",
    "R = qp.PDF(histogram=histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test interpolation at a single point for the quantile and histogram representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(P.approximate(0.314, using='quantiles'))\n",
    "#print(P.approximate(0.314, using='histogram'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's interpolate the function over an evenly spaced grid with points within and out of the quantile range.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3., 3., 100)\n",
    "P.approximate(grid, using='quantiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the PDF object in order to compare the truth and the approximation.  The solid line shows the true PDF evaluated between the bounds.  The dashed lines show the 10 percentiles that we asked for. 10% of the total probability mass is enclosed between each pair. Note that the quantiles refer to the probability distribution *between the bounds*, because we are not able to integrate numerically over an infinite range.  The red, dotted line shows an interpolation (and extrapolation) based on the quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bounds = (-3.0, 3.0)\n",
    "P.plot(limits=bounds, points=grid)\n",
    "\n",
    "T.plot(limits=bounds, points=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, let's compare the quantile approximation to the truth using the Kullback-Leibler Divergence (KLD).  The KLD is a measure of how close two probability distributions are to one another -- a smaller value indicates closer agreement.  It is measured in units of bits of information, the information lost in going from the second distribution to the first distribution.  The KLD calculator here takes in a shared grid upon which to evaluate the true distribution and the interpolated quantile approximation of that distribution and returns the KLD of the approximation relative to the truth, which is not in general the same as the KLD of the truth relative to the approximation.  Below, we'll calculate the KLD of the approximation relative to the truth over different ranges, showing that it increases as it includes areas where the true distribution and interpolated distribution diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qD1 = qp.utils.calculate_kl_divergence(P, Q, limits=(-1.,1.))\n",
    "qD2 = qp.utils.calculate_kl_divergence(P, Q, limits=(-2.,2.))\n",
    "qD3 = qp.utils.calculate_kl_divergence(P, Q, limits=(-3.,3.))\n",
    "\n",
    "hD1 = qp.utils.calculate_kl_divergence(T, R, limits=(-1.,1.))\n",
    "hD2 = qp.utils.calculate_kl_divergence(T, R, limits=(-2.,2.))\n",
    "hD3 = qp.utils.calculate_kl_divergence(T, R, limits=(-3.,3.))\n",
    "\n",
    "print(qD1, qD2, qD3)\n",
    "print(hD1, hD2, hD3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The progression of KLD values should follow that of the root mean square (RMS), another measure of how close two functions are to one another.  The RMS also increases as it includes areas where the true distribution and interpolated distribution diverge.  Unlike the KLD, the RMS is symmetric, meaning the distance measured is not that of one distribution from the other but of the symmetric distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qRMS1 = qp.utils.calculate_rms(P, Q, limits=(-1.,1.))\n",
    "qRMS2 = qp.utils.calculate_rms(P, Q, limits=(-2.,2.))\n",
    "qRMS3 = qp.utils.calculate_rms(P, Q, limits=(-3.,3.))\n",
    "\n",
    "hRMS1 = qp.utils.calculate_rms(T, R, limits=(-1.,1.))\n",
    "hRMS2 = qp.utils.calculate_rms(T, R, limits=(-2.,2.))\n",
    "hRMS3 = qp.utils.calculate_rms(T, R, limits=(-3.,3.))\n",
    "\n",
    "print(qRMS1, qRMS2, qRMS3)\n",
    "print(hRMS1, hRMS2, hRMS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
